---
title: "Linear Regression"
description: ""
number-sections: true
title-block-banner: "#00868B"
title-block-banner-color: "white"
---

```{r}
#| echo: false

library(tidyverse)

student_performance <- read_csv("datasets/StudentPerformanceFactors.csv")

student_performance <- student_performance |>
    mutate(
        Extracurricular_Activities = case_when(
            Extracurricular_Activities == "Yes" ~ TRUE,
            Extracurricular_Activities == "No" ~ FALSE,
            TRUE ~ NA
        ),
        Internet_Access = case_when(
            Internet_Access == "Yes" ~ TRUE,
            Internet_Access == "No" ~ FALSE,
            TRUE ~ NA
        ),
        Learning_Disabilities = case_when(
            Learning_Disabilities == "Yes" ~ TRUE,
            Learning_Disabilities == "No" ~ FALSE,
            TRUE ~ NA
        )
    ) |>
    rename(
        hours_studied = Hours_Studied,
        attendance = Attendance,
        parental_involvement = Parental_Involvement,
        access_to_resources = Access_to_Resources,
        extracurricular_activities = Extracurricular_Activities,
        sleep_hours = Sleep_Hours,
        previous_scores = Previous_Scores,
        motivation_level = Motivation_Level,
        internet_access = Internet_Access,
        tutoring_sessions = Tutoring_Sessions,
        family_income = Family_Income,
        teacher_quality = Teacher_Quality,
        school_type = School_Type,
        peer_influence = Peer_Influence,
        physical_activity = Physical_Activity,
        learning_disabilities = Learning_Disabilities,
        parental_education_level = Parental_Education_Level,
        distance_from_home = Distance_from_Home,
        gender = Gender,
        exam_score = Exam_Score,
    )
```

The `student_performance` dataset is a large educational dataset that seeks to capture the many different factors that can influence how well a student performs on their final exam. The fundamental research question behind this dataset is: *what predicts student academic achievement, and how strongly does each factor contribute?* This dataset is publicly available on the Kaggle platform, where it was published under the title [Student Performance Factors] (https://www.kaggle.com/datasets/lainguyn123/student-performance-factors). The dataset contains 6,607 observations, where each observation represents one individual student. For each student, 20 variables have been recorded. One of these variables is the outcome we want to predict (dependent variable), and the remaining 19 are potential predictors (independent variables). Let us walk you through each of them:

- "hours_studied" records how many hours per week each student dedicates to studying ranged from 1 to 44 hours,

- "attendance" represents the percentage of classes each student attended during the course,

- "parental_involvement" describes the degree to which a student's parents are involved in their education within the three levels (Low, Medium, and High),

- "access_to_resources" indicates the level of access a student has to educational resources such as textbooks, computers, or online materials within the three levels (Low, Medium, and High),

- "extracurricular_activities" records whether the student participates in extracurricular activities (`TRUE` or `FALSE`),

- "sleep_hours" records the average number of hours of sleep the student gets per night,

- "previous_scores" captures the student's scores from prior academic assessments ranged from 50 to 100,

- "motivation_level" captures the student's self-reported level of motivation within the three categories (Low, Medium, and High),

- "internet_access" indicates whether the student has access to the internet (`TRUE` or `FALSE`),

- "tutoring_sessions" records the number of tutoring sessions the student attended ranged from 0 to 8,

- "family_income" records the economic status of the student's family, categorized as Low, Medium, or High,

- "teacher_quality" describes the perceived quality of the student's teachers, categorized as Low, Medium, or High,

- "school_type" indicates whether the student attends a public or private school,

- "peer_influence" describes the nature of the influence the student's peer group has on their academic behavior, and it has three levels (Negative, Neutral, and Positive),

- "physical_activity" measures how many hours per week the student spends on physical activities,

- "learning_disabilities" records whether the student has been diagnosed with any learning disabilities (`TRUE` or `FALSE`),

- "parental_education_level" captures the highest level of education achieved by the student's parents, with categories including High School, College, and Postgraduate.

- "distance_from_home" indicates how far the student lives from their school, categorized as Near, Moderate, or Far,

- "gender" records the student's gender as either Male or Female,

- "exam_score" records the score that each student achieved on their final exam ranged from 55 to 101 points.

```{r}
# Pregled podataka
str(student_performance)
```

**Linear regression** is one of the oldest, most fundamental, and most widely used methods in statistics and statistical learning. Despite its simplicity, it remains an essential tool for anyone working with data, especially in the social sciences. The core idea behind linear regression is straightforward: we want to understand and quantify the relationship between one or more explanatory variables and a single outcome variable. More specifically, linear regression assumes that the relationship between the dependent and the independent variable can be described, at least approximately, by a straight line - or in the case of multiple predictors, by a flat surface (a hyperplane) in higher-dimensional space.

The purpose of linear regression is twofold. First, it serves an explanatory purpose: it helps us understand which factors are associated with the outcome and how strongly each factor contributes, while holding the other factors constant. Second, it serves a predictive purpose: once we have estimated the relationship, we can use it to predict the outcome for new observations based on their predictor values. In our student performance example, the central question is: *what factors influence a student's exam score, and by how much?* Linear regression allows us to answer questions such as "*does studying more hours lead to higher exam scores?*" and "*how much additional score can a student expect to gain for each additional hour of study?*"

The simplest form of linear regression involves just one predictor variable. This is called **simple linear regression**. Mathematically, it takes the form:

$Y \approx \beta_0 + \beta_1X$

In this equation, Y is the dependent variable - the outcome we want to predict. In our example, Y is, for example, the "exam_score". X is the independent variable - the factor we believe is related to the outcome. For instance, X could be "hours_studied". The symbol $\beta_0$ is called the **intercept**. It represents the expected value of Y when X equals zero. In our context, it would represent the expected exam score for a hypothetical student who studies zero hours. The symbol $\beta_1$ is called the **slope**. It represents the average change in Y that is associated with a one-unit increase in X. In our example, it tells us how many additional points on the exam a student can expect to gain for each additional hour of studying. Together, $\beta_0$ and $\beta_1$ are called the **model coefficients or parameters**.

Of course, in real life we do not know the true values of $\beta_0$ and $\beta_1$. We must estimate them from the data. Once we have estimated these coefficients - and we denote the estimates with a hat symbol as $\hat{\beta}_0$ and $\hat{\beta}_1$ - we can write our prediction equation as: $y = \hat{\beta_0} + \hat{\beta_1}x$. Here, $\hat{y}$ is the predicted value of the response for a given value x of the predictor. The hat symbol always indicates that we are dealing with an estimate rather than a true, known quantity.

In practice, a single predictor is rarely sufficient to explain all the variation in the response. A student's exam score is not determined by study hours alone - attendance, prior academic performance, tutoring, and many other factors play a role. **Multiple linear regression** extends the simple model to accommodate several predictors simultaneously. The general formula is:

$Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_pX_p + \eta$

In this equation, $X_1, X_2, X_3, ..., X_p$ represent p different predictor variables, and $\beta_1, \beta_2, ..., \betap$ are their corresponding slope coefficients. Each coefficient $\beta_j$ represents the average change in Y associated with a one-unit increase in the predictor $\beta_j$, while holding all other predictors constant. This "holding all other predictors constant" interpretation is crucial and is what distinguishes multiple regression from simply running many separate simple regressions. The term $\epsilon$ represents the error term - it captures everything that our model does not explain, including the influence of unmeasured variables, measurement error, and the inherent randomness in human behavior.

In our Student Performance example, a multiple linear regression model might look like this:

exam_score = $\beta_0$ + $\beta_1$ × hours_studied + $\beta_2$ × attendance + $\beta_3$ × previous_scores + $\beta_4$ × sleep_hours + $\beta_5$ × tutoring_sessions + $\beta_6$ × physical_activity + $\epsilon$

This model allows us to estimate the unique contribution of each predictor to the exam score. For instance, $\beta_1$ tells us the expected change in exam score for each additional hour of study, after accounting for the effects of attendance, previous scores, sleep, tutoring, and physical activity. This is fundamentally different from simple linear regression, where $\beta_1$ would capture the total association between study hours and exam scores without adjusting for any other factor.

## Estimating the Coefficients

The key question is: *how do we actually find the best values for our coefficient estimates $\hat{\beta}_0$, $\hat{\beta}_1$, ..., $\hat{\beta}_p$?* The answer lies in the **least squares method**, which is the most common approach for fitting a linear regression model. The basic idea is intuitive: we want our predicted values $\hat{y}_i$ to be as close as possible to the actual observed values $y_0$ for every observation in our dataset.

For each observation i, the difference between the observed value and the predicted value is called the **residual**, denoted $e_i = y_i - \hat{y}_i$. The residual tells us how much our model's prediction misses the actual outcome for that particular student. Some residuals will be positive (when the model underpredicts) and some will be negative (when the model overpredicts). To get an overall measure of how well the model fits all the data, we cannot simply add up the residuals, because the positive and negative ones would cancel each other out. Instead, we square each residual and then sum them all up. This quantity is called the **residual sum of squares** (RSS):

$RSS = e_1^2 + e_2^2 + ... + e_n^2 = \sum(y_i - \hat{y}_i)^2$

The least squares method chooses the coefficient estimates $\hat{\beta}_0$, $\hat{\beta}_1$, ..., $\hat{\beta}_p$ that minimize this RSS. In other words, the least squares approach finds the line (in simple regression) or the hyperplane (in multiple regression) that makes the total squared prediction error as small as possible. This is a well-defined mathematical optimization problem, and the solution can be computed using calculus. For simple linear regression, the formulas for the minimizers have a closed-form expression:

$\hat{\beta}_1 = \frac{\sum_{i = 1}^n(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i = 1}^n(x_i - \bar{x})^2}$

$\hat{\beta}_0 = \bar{y} - \hat{\beta}_1\hat{x}$

Here, $\bar{x}$ and $\bar{y}$ are the sample means of the predictor and the response, respectively. The formula for $\hat{\beta}_1$ has an intuitive interpretation: it measures the degree to which X and Y vary together (the numerator captures their joint variation) relative to the total variation in X (the denominator). For multiple linear regression, the coefficient estimates are computed using matrix algebra, which is handled automatically by statistical software such as R.

The beauty of the least squares method is that it provides a principled, objective way to estimate the model parameters. It does not require any subjective judgment about what the "best" line should look like - the method simply finds the line that minimizes the total squared distance between the observed data points and the fitted line.

## Applying Linear Regression to Our Example in R

Now let us apply these concepts to our `student_performance` dataset. We will fit both a simple linear regression (predicting "exam_score" from "hours_studied" alone) and a multiple linear regression (predicting "exam_score" from six quantitative predictors). Below is the R code that accomplishes this.

To fit a simple linear regression model in R, we use the `lm()` function, which stands for linear model. The syntax follows the pattern `lm(response ~ predictor, data = dataset)`. The tilde symbol (`~`) can be read as "*is modeled as a function of*". For our simple linear regression of "exam_score" onto "hours_studied", we write:

```{r}
simple_model <- lm(exam_score ~ hours_studied, data = student_performance)
summary(simple_model)
confint(simple_model)
```

The `lm()` function fits the model by computing the least squares coefficient estimates. The `summary()` function then provides a detailed output that includes the estimated coefficients, their standard errors, t-statistics, p-values, the residual standard error, and the $R^2$ statistic. The `confint()` function computes the 95% confidence intervals for each coefficient estimate, which tell us the range of plausible values for the true population parameters.

The first block of the output reports a summary of the residuals — the differences between the actual exam scores and the scores predicted by the model. R provides five summary statistics: the minimum residual (-8.532), the first quartile (-2.243), the median (-0.111), the third quartile (2.046), and the maximum residual (33.493). These numbers give us a quick sense of how the model's prediction errors are distributed. Ideally, we would like the residuals to be roughly symmetrically distributed around zero, which would indicate that the model overpredicts and underpredicts with roughly equal frequency and magnitude. In our case, the median is very close to zero (-0.111), and the first and third quartiles are roughly symmetric in magnitude (-2.243 and 2.046), which is encouraging. However, the maximum residual of 33.493 is strikingly large compared to the minimum of -8.532. This tells us that there is at least one student whose actual exam score was about 33.5 points higher than what the model predicted. This large positive outlier suggests that there are some unusually high-performing students whose scores are not well explained by study hours alone — something we should keep in mind and investigate further.

The coefficients table is the heart of the regression output. It reports four pieces of information for each coefficient: the estimate, its standard error, the t-statistic, and the p-value.

The intercept (β̂₀) is estimated at 61.457. This means that when Hours_Studied equals zero, the model predicts an exam score of approximately 61.46 points. In substantive terms, a hypothetical student who does not study at all would be expected to score about 61.5 on the exam, according to this model. This makes intuitive sense — students would still have some baseline level of knowledge from attending classes, even without additional study outside the classroom.

The slope for Hours_Studied (β̂₁) is estimated at 0.289. This is the key coefficient for our research question. It tells us that for each additional hour of study per week, a student's exam score is expected to increase by approximately 0.29 points, on average. So a student who studies 10 hours more per week than another student would be expected to score about 2.89 points higher on the exam. The direction of the relationship is positive, which aligns with our intuition that more studying leads to better performance.

The standard error of each coefficient tells us how precisely the coefficient has been estimated. For the intercept, the standard error is 0.149, and for the slope it is 0.00715. These are quite small relative to the coefficient estimates themselves, which indicates that our estimates are very precise — this is largely a consequence of having a very large sample size of 6,607 observations. The larger the sample, the more precisely we can estimate the regression coefficients, because we have more information to work with.

The t-statistic is calculated by dividing the coefficient estimate by its standard error. For the intercept, the t-value is 411.92 (which is 61.457 divided by 0.149), and for Hours_Studied the t-value is 40.44 (which is 0.289 divided by 0.00715). The t-statistic measures how many standard errors the coefficient estimate is away from zero. A large t-statistic indicates that the coefficient is far from zero relative to its uncertainty, which provides strong evidence that the true coefficient is not zero.

The p-value, shown in the column labeled Pr(>|t|), tells us the probability of observing a t-statistic as extreme as the one we calculated, under the assumption that the true coefficient is actually zero (that is, under the null hypothesis that there is no relationship between the predictor and the response). For both the intercept and Hours_Studied, the p-value is reported as less than 2 × 10⁻¹⁶, which is essentially zero. This means that the probability of seeing such strong evidence for a relationship if no relationship actually existed is vanishingly small. The three asterisks (***) next to the p-values indicate the highest level of statistical significance. We can therefore confidently reject the null hypothesis that β₁ = 0, and conclude that there is a statistically significant positive relationship between Hours_Studied and Exam_Score.

Below the coefficients table, R provides several statistics that describe the overall quality of the model.

The Residual Standard Error (RSE) is 3.483. This is an estimate of the standard deviation of the error term ε. In practical terms, it tells us that the actual exam scores deviate from the model's predictions by approximately 3.48 points on average. Given that the mean exam score is about 67.24, this represents a percentage error of roughly 5.2% (3.483 / 67.24), which is moderate. It means that even after accounting for study hours, there is still considerable unexplained variation in exam scores — many other factors besides study time contribute to how well a student performs.

The R² (R-squared) statistic is 0.1984. This is one of the most important measures of model fit. R² represents the proportion of the total variance in the response variable that is explained by the model. In our case, R² = 0.1984 means that Hours_Studied alone explains approximately 19.84% of the variation in exam scores. The remaining 80% of the variation is due to other factors that are not included in this model. While 19.84% is a meaningful amount of explanatory power — it confirms that study hours do matter — it also makes clear that study hours alone are far from sufficient to explain student performance. This is exactly what motivates us to move from simple to multiple linear regression: by adding more predictors, we hope to explain a larger share of the variation.

The Adjusted R² is 0.1983, which is virtually identical to the regular R² in this case. The adjusted version penalizes the model slightly for each additional predictor it includes, to guard against the artificial inflation of R² that occurs when irrelevant predictors are added. With only one predictor, the penalty is negligible, so the two values are nearly the same.

The F-statistic is 1,635, with a p-value less than 2.2 × 10⁻¹⁶. The F-statistic tests the overall null hypothesis that all slope coefficients in the model are zero — in other words, that none of the predictors are related to the response. In simple linear regression with just one predictor, this test is equivalent to the t-test for β₁. The extremely large F-statistic and the essentially zero p-value confirm that the model as a whole is statistically significant: Hours_Studied is clearly related to Exam_Score.

The confidence intervals provide a range of plausible values for each true population coefficient. For the intercept, the 95% confidence interval is [61.16, 61.75], meaning we are 95% confident that the true baseline exam score (when study hours are zero) lies between 61.16 and 61.75 points. For Hours_Studied, the 95% confidence interval is [0.275, 0.303]. This means we are 95% confident that the true effect of one additional hour of study is an increase in exam score between 0.275 and 0.303 points. Importantly, this interval does not include zero, which is consistent with our finding that the relationship is statistically significant. If zero were included in this interval, it would mean that a null effect (no relationship) would be a plausible value, and we could not reject the null hypothesis.

For the multiple linear regression model, we simply add more predictors to the right side of the formula, separated by the + sign:

```{r}
multiple_model <- lm(exam_score ~ hours_studied + attendance + previous_scores + sleep_hours + tutoring_sessions + physical_activity, data = student_performance)
summary(multiple_model)
confint(multiple_model)
```

This tells R to fit a model that predicts "exam_score" using all six quantitative predictors simultaneously. The least squares method will estimate a separate slope coefficient for each predictor, along with a single intercept, by minimizing the total RSS across all 6,607 observations.

Our multiple linear regression model includes six quantitative predictors simultaneously. The estimated model can be written as:

Exam_Score ≈ 40.93 + 0.292 × Hours_Studied + 0.198 × Attendance + 0.048 × Previous_Scores − 0.018 × Sleep_Hours + 0.494 × Tutoring_Sessions + 0.144 × Physical_Activity

Compared to the simple model, the residuals in the multiple regression are noticeably tighter. The minimum is -5.44 and the third quartile is 0.84, meaning that for most students, the model's predictions are off by less than about one point. The median residual is -0.16, which is very close to zero, indicating that the model does not systematically overpredict or underpredict. However, the maximum residual is still 30.99, indicating that there remains at least one extreme outlier — a student who scored about 31 points higher than predicted. This is slightly smaller than in the simple model (where the maximum was 33.49), suggesting that adding more predictors has helped but has not fully resolved this issue.

The intercept (β̂₀) is now estimated at 40.927. This is substantially lower than in the simple model (61.46), which makes sense. In the simple model, the intercept represented the predicted score when only Hours_Studied was zero. In the multiple model, the intercept represents the predicted score when all six predictors are simultaneously zero — that is, a hypothetical student who studies zero hours, has zero attendance, has zero previous scores, gets zero sleep, has zero tutoring sessions, and does zero physical activity. Such a student is of course entirely hypothetical and unrealistic, which is why we should not over-interpret the intercept in multiple regression. Its main role is mathematical — it anchors the regression plane in the right position.

The coefficient for Hours_Studied is 0.292, which is remarkably similar to its value in the simple regression (0.289). This tells us something important: the relationship between study hours and exam scores is robust — it persists even after we account for the effects of attendance, prior scores, sleep, tutoring, and physical activity. In substantive terms, holding all other factors constant, each additional hour of study per week is associated with an increase of about 0.29 points on the exam. The t-statistic is 57.52 and the p-value is far below any conventional significance threshold, confirming that this relationship is highly statistically significant.

The coefficient for Attendance is 0.198, meaning that each additional percentage point of class attendance is associated with about 0.20 additional points on the exam, after controlling for the other variables. To put this in perspective, a student who attends 90% of classes versus one who attends 70% of classes (a 20 percentage-point difference) would be expected to score about 3.96 points higher, all else being equal. The t-statistic of 75.26 makes this the strongest predictor in the model, and its p-value is essentially zero.

The coefficient for Previous_Scores is 0.048. This means that for each additional point a student earned on their previous assessments, their exam score is expected to increase by about 0.048 points, holding other factors constant. While this effect is statistically significant (t = 22.81, p < 2 × 10⁻¹⁶), it is relatively modest in magnitude. A student whose prior scores are 20 points higher than another student's would be expected to score only about 0.96 points higher on this exam. This suggests that while past performance does predict future performance, its incremental contribution is small once study habits and attendance are already accounted for.

The coefficient for Sleep_Hours is -0.018. This is the only predictor whose coefficient is not statistically significant in this model. The t-statistic is only -0.871, and the p-value is 0.384 — far above any conventional significance threshold such as 0.05 or 0.01. This means that we cannot reject the null hypothesis that the true coefficient for Sleep_Hours is zero. In other words, after accounting for study hours, attendance, prior scores, tutoring, and physical activity, sleep hours do not appear to have a meaningful linear relationship with exam scores. This does not necessarily mean that sleep is unimportant for academic performance in general — it may be that the effect of sleep is nonlinear, or that its influence is already captured indirectly by the other variables in the model.

The coefficient for Tutoring_Sessions is 0.494, the largest individual slope coefficient in the model. Each additional tutoring session is associated with about half a point increase on the exam. A student who attended 4 tutoring sessions compared to one who attended none would be expected to score about 1.97 points higher. The t-statistic is 20.00 and the p-value is essentially zero, confirming strong statistical significance.

The coefficient for Physical_Activity is 0.144, meaning that each additional hour per week of physical activity is associated with about 0.14 additional exam points, after controlling for the other variables. The t-statistic is 4.89 and the p-value is approximately 0.000001, so this relationship is statistically significant, though its practical magnitude is relatively small.

The Residual Standard Error has decreased from 3.483 in the simple model to 2.467 in the multiple model. This is a substantial improvement — it tells us that the average prediction error has been reduced by about 29%. The model's predictions are now off by only about 2.47 points on average, compared to 3.48 points when we used study hours alone.

The R² has jumped from 0.1984 to 0.5982. This is a dramatic improvement. The multiple regression model now explains approximately 59.82% of the variation in exam scores, compared to only 19.84% in the simple model. Adding attendance, previous scores, tutoring sessions, and physical activity has nearly tripled the amount of explained variance. The Adjusted R² is 0.5979, which is nearly identical to the regular R², indicating that the additional predictors are genuinely contributing to the model's explanatory power and are not merely inflating R² artificially.

The F-statistic is 1,638 with a p-value less than 2.2 × 10⁻¹⁶. In the multiple regression context, the F-statistic tests the null hypothesis that all slope coefficients are simultaneously zero (H₀: β₁ = β₂ = ... = β₆ = 0). The enormous F-statistic and the effectively zero p-value tell us that we can decisively reject this null hypothesis. At least some — and as we saw, most — of the predictors are significantly related to exam scores.

The confidence intervals for the multiple regression coefficients reinforce our findings. For Hours_Studied, the interval is [0.282, 0.302], which is narrow and entirely above zero — strong evidence of a positive effect. For Attendance, the interval is [0.193, 0.203], also narrow and firmly positive. For Tutoring_Sessions, it is [0.445, 0.542]. For Physical_Activity, it is [0.086, 0.202]. All of these intervals exclude zero, confirming statistical significance.

The crucial exception is Sleep_Hours, whose confidence interval is [-0.059, 0.023]. This interval straddles zero — it includes both negative and positive values — which confirms that we cannot determine with confidence whether sleep hours have a positive, negative, or zero effect on exam scores in this model. This is perfectly consistent with the non-significant p-value of 0.384 that we observed for this variable.

The comparison between the two models illustrates several important principles from the textbook. First, the coefficient for Hours_Studied barely changed between the simple model (0.289) and the multiple model (0.292). This stability suggests that Hours_Studied is not strongly confounded with the other predictors — its relationship with exam scores is genuine and not merely a byproduct of its correlation with other variables. Second, the dramatic increase in R² from 0.198 to 0.598 demonstrates that multiple regression can be far more powerful than simple regression when there are indeed multiple factors at play. Third, the non-significance of Sleep_Hours reminds us that not every predictor we include will turn out to be useful — and this is exactly the kind of finding that helps us build a more parsimonious model by identifying which variables can be dropped without meaningful loss of explanatory power.
