<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Linear Regression – Statistical Learning in R for Social Sciences</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./introduction_to_statistical_learning.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-86b712c1a9842e5c5be4cb0afbdd663e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: white;
      }

      .quarto-title-block .quarto-title-banner {
        color: white;
background: #00868B;
      }
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./linear_regression.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Linear Regression</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Linear Regression</span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Statistical Learning in R for Social Sciences</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction_to_statistical_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Statistical Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear_regression.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Linear Regression</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#estimating-the-coefficients" id="toc-estimating-the-coefficients" class="nav-link active" data-scroll-target="#estimating-the-coefficients"><span class="header-section-number">2.1</span> Estimating the Coefficients</a></li>
  <li><a href="#applying-linear-regression-to-our-example-in-r" id="toc-applying-linear-regression-to-our-example-in-r" class="nav-link" data-scroll-target="#applying-linear-regression-to-our-example-in-r"><span class="header-section-number">2.2</span> Applying Linear Regression to Our Example in R</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.6
✔ forcats   1.0.1     ✔ stringr   1.6.0
✔ ggplot2   4.0.1     ✔ tibble    3.3.1
✔ lubridate 1.9.4     ✔ tidyr     1.3.2
✔ purrr     1.2.1     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors
Rows: 6607 Columns: 20
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
chr (13): Parental_Involvement, Access_to_Resources, Extracurricular_Activit...
dbl  (7): Hours_Studied, Attendance, Sleep_Hours, Previous_Scores, Tutoring_...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
</div>
</div>
<p>The <code>student_performance</code> dataset is a large educational dataset that seeks to capture the many different factors that can influence how well a student performs on their final exam. The fundamental research question behind this dataset is: <em>what predicts student academic achievement, and how strongly does each factor contribute?</em> This dataset is publicly available on the Kaggle platform, where it was published under the title [Student Performance Factors] (https://www.kaggle.com/datasets/lainguyn123/student-performance-factors). The dataset contains 6,607 observations, where each observation represents one individual student. For each student, 20 variables have been recorded. One of these variables is the outcome we want to predict (dependent variable), and the remaining 19 are potential predictors (independent variables). Let us walk you through each of them:</p>
<ul>
<li><p>“hours_studied” records how many hours per week each student dedicates to studying ranged from 1 to 44 hours,</p></li>
<li><p>“attendance” represents the percentage of classes each student attended during the course,</p></li>
<li><p>“parental_involvement” describes the degree to which a student’s parents are involved in their education within the three levels (Low, Medium, and High),</p></li>
<li><p>“access_to_resources” indicates the level of access a student has to educational resources such as textbooks, computers, or online materials within the three levels (Low, Medium, and High),</p></li>
<li><p>“extracurricular_activities” records whether the student participates in extracurricular activities (<code>TRUE</code> or <code>FALSE</code>),</p></li>
<li><p>“sleep_hours” records the average number of hours of sleep the student gets per night,</p></li>
<li><p>“previous_scores” captures the student’s scores from prior academic assessments ranged from 50 to 100,</p></li>
<li><p>“motivation_level” captures the student’s self-reported level of motivation within the three categories (Low, Medium, and High),</p></li>
<li><p>“internet_access” indicates whether the student has access to the internet (<code>TRUE</code> or <code>FALSE</code>),</p></li>
<li><p>“tutoring_sessions” records the number of tutoring sessions the student attended ranged from 0 to 8,</p></li>
<li><p>“family_income” records the economic status of the student’s family, categorized as Low, Medium, or High,</p></li>
<li><p>“teacher_quality” describes the perceived quality of the student’s teachers, categorized as Low, Medium, or High,</p></li>
<li><p>“school_type” indicates whether the student attends a public or private school,</p></li>
<li><p>“peer_influence” describes the nature of the influence the student’s peer group has on their academic behavior, and it has three levels (Negative, Neutral, and Positive),</p></li>
<li><p>“physical_activity” measures how many hours per week the student spends on physical activities,</p></li>
<li><p>“learning_disabilities” records whether the student has been diagnosed with any learning disabilities (<code>TRUE</code> or <code>FALSE</code>),</p></li>
<li><p>“parental_education_level” captures the highest level of education achieved by the student’s parents, with categories including High School, College, and Postgraduate.</p></li>
<li><p>“distance_from_home” indicates how far the student lives from their school, categorized as Near, Moderate, or Far,</p></li>
<li><p>“gender” records the student’s gender as either Male or Female,</p></li>
<li><p>“exam_score” records the score that each student achieved on their final exam ranged from 55 to 101 points.</p></li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pregled podataka</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(student_performance)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>tibble [6,607 × 20] (S3: tbl_df/tbl/data.frame)
 $ hours_studied             : num [1:6607] 23 19 24 29 19 19 29 25 17 23 ...
 $ attendance                : num [1:6607] 84 64 98 89 92 88 84 78 94 98 ...
 $ parental_involvement      : chr [1:6607] "Low" "Low" "Medium" "Low" ...
 $ access_to_resources       : chr [1:6607] "High" "Medium" "Medium" "Medium" ...
 $ extracurricular_activities: logi [1:6607] FALSE FALSE TRUE TRUE TRUE TRUE ...
 $ sleep_hours               : num [1:6607] 7 8 7 8 6 8 7 6 6 8 ...
 $ previous_scores           : num [1:6607] 73 59 91 98 65 89 68 50 80 71 ...
 $ motivation_level          : chr [1:6607] "Low" "Low" "Medium" "Medium" ...
 $ internet_access           : logi [1:6607] TRUE TRUE TRUE TRUE TRUE TRUE ...
 $ tutoring_sessions         : num [1:6607] 0 2 2 1 3 3 1 1 0 0 ...
 $ family_income             : chr [1:6607] "Low" "Medium" "Medium" "Medium" ...
 $ teacher_quality           : chr [1:6607] "Medium" "Medium" "Medium" "Medium" ...
 $ school_type               : chr [1:6607] "Public" "Public" "Public" "Public" ...
 $ peer_influence            : chr [1:6607] "Positive" "Negative" "Neutral" "Negative" ...
 $ physical_activity         : num [1:6607] 3 4 4 4 4 3 2 2 1 5 ...
 $ learning_disabilities     : logi [1:6607] FALSE FALSE FALSE FALSE FALSE FALSE ...
 $ parental_education_level  : chr [1:6607] "High School" "College" "Postgraduate" "High School" ...
 $ distance_from_home        : chr [1:6607] "Near" "Moderate" "Near" "Moderate" ...
 $ gender                    : chr [1:6607] "Male" "Female" "Male" "Male" ...
 $ exam_score                : num [1:6607] 67 61 74 71 70 71 67 66 69 72 ...</code></pre>
</div>
</div>
<p><strong>Linear regression</strong> is one of the oldest, most fundamental, and most widely used methods in statistics and statistical learning. Despite its simplicity, it remains an essential tool for anyone working with data, especially in the social sciences. The core idea behind linear regression is straightforward: we want to understand and quantify the relationship between one or more explanatory variables and a single outcome variable. More specifically, linear regression assumes that the relationship between the dependent and the independent variable can be described, at least approximately, by a straight line - or in the case of multiple predictors, by a flat surface (a hyperplane) in higher-dimensional space.</p>
<p>The purpose of linear regression is twofold. First, it serves an explanatory purpose: it helps us understand which factors are associated with the outcome and how strongly each factor contributes, while holding the other factors constant. Second, it serves a predictive purpose: once we have estimated the relationship, we can use it to predict the outcome for new observations based on their predictor values. In our student performance example, the central question is: <em>what factors influence a student’s exam score, and by how much?</em> Linear regression allows us to answer questions such as “<em>does studying more hours lead to higher exam scores?</em>” and “<em>how much additional score can a student expect to gain for each additional hour of study?</em>”</p>
<p>The simplest form of linear regression involves just one predictor variable. This is called <strong>simple linear regression</strong>. Mathematically, it takes the form:</p>
<p><span class="math inline">\(Y \approx \beta_0 + \beta_1X\)</span></p>
<p>In this equation, Y is the dependent variable - the outcome we want to predict. In our example, Y is, for example, the “exam_score”. X is the independent variable - the factor we believe is related to the outcome. For instance, X could be “hours_studied”. The symbol <span class="math inline">\(\beta_0\)</span> is called the <strong>intercept</strong>. It represents the expected value of Y when X equals zero. In our context, it would represent the expected exam score for a hypothetical student who studies zero hours. The symbol <span class="math inline">\(\beta_1\)</span> is called the <strong>slope</strong>. It represents the average change in Y that is associated with a one-unit increase in X. In our example, it tells us how many additional points on the exam a student can expect to gain for each additional hour of studying. Together, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are called the <strong>model coefficients or parameters</strong>.</p>
<p>Of course, in real life we do not know the true values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. We must estimate them from the data. Once we have estimated these coefficients - and we denote the estimates with a hat symbol as <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> - we can write our prediction equation as: <span class="math inline">\(y = \hat{\beta_0} + \hat{\beta_1}x\)</span>. Here, <span class="math inline">\(\hat{y}\)</span> is the predicted value of the response for a given value x of the predictor. The hat symbol always indicates that we are dealing with an estimate rather than a true, known quantity.</p>
<p>In practice, a single predictor is rarely sufficient to explain all the variation in the response. A student’s exam score is not determined by study hours alone - attendance, prior academic performance, tutoring, and many other factors play a role. <strong>Multiple linear regression</strong> extends the simple model to accommodate several predictors simultaneously. The general formula is:</p>
<p><span class="math inline">\(Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_pX_p + \eta\)</span></p>
<p>In this equation, <span class="math inline">\(X_1, X_2, X_3, ..., X_p\)</span> represent p different predictor variables, and <span class="math inline">\(\beta_1, \beta_2, ..., \betap\)</span> are their corresponding slope coefficients. Each coefficient <span class="math inline">\(\beta_j\)</span> represents the average change in Y associated with a one-unit increase in the predictor <span class="math inline">\(\beta_j\)</span>, while holding all other predictors constant. This “holding all other predictors constant” interpretation is crucial and is what distinguishes multiple regression from simply running many separate simple regressions. The term <span class="math inline">\(\epsilon\)</span> represents the error term - it captures everything that our model does not explain, including the influence of unmeasured variables, measurement error, and the inherent randomness in human behavior.</p>
<p>In our Student Performance example, a multiple linear regression model might look like this:</p>
<p>exam_score = <span class="math inline">\(\beta_0\)</span> + <span class="math inline">\(\beta_1\)</span> × hours_studied + <span class="math inline">\(\beta_2\)</span> × attendance + <span class="math inline">\(\beta_3\)</span> × previous_scores + <span class="math inline">\(\beta_4\)</span> × sleep_hours + <span class="math inline">\(\beta_5\)</span> × tutoring_sessions + <span class="math inline">\(\beta_6\)</span> × physical_activity + <span class="math inline">\(\epsilon\)</span></p>
<p>This model allows us to estimate the unique contribution of each predictor to the exam score. For instance, <span class="math inline">\(\beta_1\)</span> tells us the expected change in exam score for each additional hour of study, after accounting for the effects of attendance, previous scores, sleep, tutoring, and physical activity. This is fundamentally different from simple linear regression, where <span class="math inline">\(\beta_1\)</span> would capture the total association between study hours and exam scores without adjusting for any other factor.</p>
<section id="estimating-the-coefficients" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="estimating-the-coefficients"><span class="header-section-number">2.1</span> Estimating the Coefficients</h2>
<p>The key question is: <em>how do we actually find the best values for our coefficient estimates <span class="math inline">\(\hat{\beta}_0\)</span>, <span class="math inline">\(\hat{\beta}_1\)</span>, …, <span class="math inline">\(\hat{\beta}_p\)</span>?</em> The answer lies in the <strong>least squares method</strong>, which is the most common approach for fitting a linear regression model. The basic idea is intuitive: we want our predicted values <span class="math inline">\(\hat{y}_i\)</span> to be as close as possible to the actual observed values <span class="math inline">\(y_0\)</span> for every observation in our dataset.</p>
<p>For each observation i, the difference between the observed value and the predicted value is called the <strong>residual</strong>, denoted <span class="math inline">\(e_i = y_i - \hat{y}_i\)</span>. The residual tells us how much our model’s prediction misses the actual outcome for that particular student. Some residuals will be positive (when the model underpredicts) and some will be negative (when the model overpredicts). To get an overall measure of how well the model fits all the data, we cannot simply add up the residuals, because the positive and negative ones would cancel each other out. Instead, we square each residual and then sum them all up. This quantity is called the <strong>residual sum of squares</strong> (RSS):</p>
<p><span class="math inline">\(RSS = e_1^2 + e_2^2 + ... + e_n^2 = \sum(y_i - \hat{y}_i)^2\)</span></p>
<p>The least squares method chooses the coefficient estimates <span class="math inline">\(\hat{\beta}_0\)</span>, <span class="math inline">\(\hat{\beta}_1\)</span>, …, <span class="math inline">\(\hat{\beta}_p\)</span> that minimize this RSS. In other words, the least squares approach finds the line (in simple regression) or the hyperplane (in multiple regression) that makes the total squared prediction error as small as possible. This is a well-defined mathematical optimization problem, and the solution can be computed using calculus. For simple linear regression, the formulas for the minimizers have a closed-form expression:</p>
<p><span class="math inline">\(\hat{\beta}_1 = \frac{\sum_{i = 1}^n(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i = 1}^n(x_i - \bar{x})^2}\)</span></p>
<p><span class="math inline">\(\hat{\beta}_0 = \bar{y} - \hat{\beta}_1\hat{x}\)</span></p>
<p>Here, <span class="math inline">\(\bar{x}\)</span> and <span class="math inline">\(\bar{y}\)</span> are the sample means of the predictor and the response, respectively. The formula for <span class="math inline">\(\hat{\beta}_1\)</span> has an intuitive interpretation: it measures the degree to which X and Y vary together (the numerator captures their joint variation) relative to the total variation in X (the denominator). For multiple linear regression, the coefficient estimates are computed using matrix algebra, which is handled automatically by statistical software such as R.</p>
<p>The beauty of the least squares method is that it provides a principled, objective way to estimate the model parameters. It does not require any subjective judgment about what the “best” line should look like - the method simply finds the line that minimizes the total squared distance between the observed data points and the fitted line.</p>
</section>
<section id="applying-linear-regression-to-our-example-in-r" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="applying-linear-regression-to-our-example-in-r"><span class="header-section-number">2.2</span> Applying Linear Regression to Our Example in R</h2>
<p>Now let us apply these concepts to our <code>student_performance</code> dataset. We will fit both a simple linear regression (predicting “exam_score” from “hours_studied” alone) and a multiple linear regression (predicting “exam_score” from six quantitative predictors). Below is the R code that accomplishes this.</p>
<p>To fit a simple linear regression model in R, we use the <code>lm()</code> function, which stands for linear model. The syntax follows the pattern <code>lm(response ~ predictor, data = dataset)</code>. The tilde symbol (<code>~</code>) can be read as “<em>is modeled as a function of</em>”. For our simple linear regression of “exam_score” onto “hours_studied”, we write:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>simple_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(exam_score <span class="sc">~</span> hours_studied, <span class="at">data =</span> student_performance)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(simple_model)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = exam_score ~ hours_studied, data = student_performance)

Residuals:
   Min     1Q Median     3Q    Max 
-8.532 -2.243 -0.111  2.046 33.493 

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   61.456984   0.149196  411.92   &lt;2e-16 ***
hours_studied  0.289291   0.007154   40.44   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.483 on 6605 degrees of freedom
Multiple R-squared:  0.1984,    Adjusted R-squared:  0.1983 
F-statistic:  1635 on 1 and 6605 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(simple_model)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                  2.5 %     97.5 %
(Intercept)   61.164511 61.7494561
hours_studied  0.275266  0.3033153</code></pre>
</div>
</div>
<p>The <code>lm()</code> function fits the model by computing the least squares coefficient estimates. The <code>summary()</code> function then provides a detailed output that includes the estimated coefficients, their standard errors, t-statistics, p-values, the residual standard error, and the <span class="math inline">\(R^2\)</span> statistic. The <code>confint()</code> function computes the 95% confidence intervals for each coefficient estimate, which tell us the range of plausible values for the true population parameters.</p>
<p>The first block of the output reports a summary of the residuals — the differences between the actual exam scores and the scores predicted by the model. R provides five summary statistics: the minimum residual (-8.532), the first quartile (-2.243), the median (-0.111), the third quartile (2.046), and the maximum residual (33.493). These numbers give us a quick sense of how the model’s prediction errors are distributed. Ideally, we would like the residuals to be roughly symmetrically distributed around zero, which would indicate that the model overpredicts and underpredicts with roughly equal frequency and magnitude. In our case, the median is very close to zero (-0.111), and the first and third quartiles are roughly symmetric in magnitude (-2.243 and 2.046), which is encouraging. However, the maximum residual of 33.493 is strikingly large compared to the minimum of -8.532. This tells us that there is at least one student whose actual exam score was about 33.5 points higher than what the model predicted. This large positive outlier suggests that there are some unusually high-performing students whose scores are not well explained by study hours alone — something we should keep in mind and investigate further.</p>
<p>The coefficients table is the heart of the regression output. It reports four pieces of information for each coefficient: the estimate, its standard error, the t-statistic, and the p-value.</p>
<p>The intercept (β̂₀) is estimated at 61.457. This means that when Hours_Studied equals zero, the model predicts an exam score of approximately 61.46 points. In substantive terms, a hypothetical student who does not study at all would be expected to score about 61.5 on the exam, according to this model. This makes intuitive sense — students would still have some baseline level of knowledge from attending classes, even without additional study outside the classroom.</p>
<p>The slope for Hours_Studied (β̂₁) is estimated at 0.289. This is the key coefficient for our research question. It tells us that for each additional hour of study per week, a student’s exam score is expected to increase by approximately 0.29 points, on average. So a student who studies 10 hours more per week than another student would be expected to score about 2.89 points higher on the exam. The direction of the relationship is positive, which aligns with our intuition that more studying leads to better performance.</p>
<p>The standard error of each coefficient tells us how precisely the coefficient has been estimated. For the intercept, the standard error is 0.149, and for the slope it is 0.00715. These are quite small relative to the coefficient estimates themselves, which indicates that our estimates are very precise — this is largely a consequence of having a very large sample size of 6,607 observations. The larger the sample, the more precisely we can estimate the regression coefficients, because we have more information to work with.</p>
<p>The t-statistic is calculated by dividing the coefficient estimate by its standard error. For the intercept, the t-value is 411.92 (which is 61.457 divided by 0.149), and for Hours_Studied the t-value is 40.44 (which is 0.289 divided by 0.00715). The t-statistic measures how many standard errors the coefficient estimate is away from zero. A large t-statistic indicates that the coefficient is far from zero relative to its uncertainty, which provides strong evidence that the true coefficient is not zero.</p>
<p>The p-value, shown in the column labeled Pr(&gt;|t|), tells us the probability of observing a t-statistic as extreme as the one we calculated, under the assumption that the true coefficient is actually zero (that is, under the null hypothesis that there is no relationship between the predictor and the response). For both the intercept and Hours_Studied, the p-value is reported as less than 2 × 10⁻¹⁶, which is essentially zero. This means that the probability of seeing such strong evidence for a relationship if no relationship actually existed is vanishingly small. The three asterisks (***) next to the p-values indicate the highest level of statistical significance. We can therefore confidently reject the null hypothesis that β₁ = 0, and conclude that there is a statistically significant positive relationship between Hours_Studied and Exam_Score.</p>
<p>Below the coefficients table, R provides several statistics that describe the overall quality of the model.</p>
<p>The Residual Standard Error (RSE) is 3.483. This is an estimate of the standard deviation of the error term ε. In practical terms, it tells us that the actual exam scores deviate from the model’s predictions by approximately 3.48 points on average. Given that the mean exam score is about 67.24, this represents a percentage error of roughly 5.2% (3.483 / 67.24), which is moderate. It means that even after accounting for study hours, there is still considerable unexplained variation in exam scores — many other factors besides study time contribute to how well a student performs.</p>
<p>The R² (R-squared) statistic is 0.1984. This is one of the most important measures of model fit. R² represents the proportion of the total variance in the response variable that is explained by the model. In our case, R² = 0.1984 means that Hours_Studied alone explains approximately 19.84% of the variation in exam scores. The remaining 80% of the variation is due to other factors that are not included in this model. While 19.84% is a meaningful amount of explanatory power — it confirms that study hours do matter — it also makes clear that study hours alone are far from sufficient to explain student performance. This is exactly what motivates us to move from simple to multiple linear regression: by adding more predictors, we hope to explain a larger share of the variation.</p>
<p>The Adjusted R² is 0.1983, which is virtually identical to the regular R² in this case. The adjusted version penalizes the model slightly for each additional predictor it includes, to guard against the artificial inflation of R² that occurs when irrelevant predictors are added. With only one predictor, the penalty is negligible, so the two values are nearly the same.</p>
<p>The F-statistic is 1,635, with a p-value less than 2.2 × 10⁻¹⁶. The F-statistic tests the overall null hypothesis that all slope coefficients in the model are zero — in other words, that none of the predictors are related to the response. In simple linear regression with just one predictor, this test is equivalent to the t-test for β₁. The extremely large F-statistic and the essentially zero p-value confirm that the model as a whole is statistically significant: Hours_Studied is clearly related to Exam_Score.</p>
<p>The confidence intervals provide a range of plausible values for each true population coefficient. For the intercept, the 95% confidence interval is [61.16, 61.75], meaning we are 95% confident that the true baseline exam score (when study hours are zero) lies between 61.16 and 61.75 points. For Hours_Studied, the 95% confidence interval is [0.275, 0.303]. This means we are 95% confident that the true effect of one additional hour of study is an increase in exam score between 0.275 and 0.303 points. Importantly, this interval does not include zero, which is consistent with our finding that the relationship is statistically significant. If zero were included in this interval, it would mean that a null effect (no relationship) would be a plausible value, and we could not reject the null hypothesis.</p>
<p>For the multiple linear regression model, we simply add more predictors to the right side of the formula, separated by the + sign:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>multiple_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(exam_score <span class="sc">~</span> hours_studied <span class="sc">+</span> attendance <span class="sc">+</span> previous_scores <span class="sc">+</span> sleep_hours <span class="sc">+</span> tutoring_sessions <span class="sc">+</span> physical_activity, <span class="at">data =</span> student_performance)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(multiple_model)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = exam_score ~ hours_studied + attendance + previous_scores + 
    sleep_hours + tutoring_sessions + physical_activity, data = student_performance)

Residuals:
    Min      1Q  Median      3Q     Max 
-5.4391 -1.1316 -0.1619  0.8435 30.9951 

Coefficients:
                   Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)       40.927132   0.338284 120.985  &lt; 2e-16 ***
hours_studied      0.291579   0.005069  57.517  &lt; 2e-16 ***
attendance         0.197978   0.002631  75.262  &lt; 2e-16 ***
previous_scores    0.048123   0.002110  22.809  &lt; 2e-16 ***
sleep_hours       -0.018022   0.020686  -0.871    0.384    
tutoring_sessions  0.493505   0.024679  19.997  &lt; 2e-16 ***
physical_activity  0.143997   0.029449   4.890 1.03e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2.467 on 6600 degrees of freedom
Multiple R-squared:  0.5982,    Adjusted R-squared:  0.5979 
F-statistic:  1638 on 6 and 6600 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(multiple_model)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                        2.5 %      97.5 %
(Intercept)       40.26398610 41.59027841
hours_studied      0.28164155  0.30151722
attendance         0.19282088  0.20313417
previous_scores    0.04398664  0.05225848
sleep_hours       -0.05857194  0.02252862
tutoring_sessions  0.44512667  0.54188355
physical_activity  0.08626812  0.20172578</code></pre>
</div>
</div>
<p>This tells R to fit a model that predicts “exam_score” using all six quantitative predictors simultaneously. The least squares method will estimate a separate slope coefficient for each predictor, along with a single intercept, by minimizing the total RSS across all 6,607 observations.</p>
<p>Our multiple linear regression model includes six quantitative predictors simultaneously. The estimated model can be written as:</p>
<p>Exam_Score ≈ 40.93 + 0.292 × Hours_Studied + 0.198 × Attendance + 0.048 × Previous_Scores − 0.018 × Sleep_Hours + 0.494 × Tutoring_Sessions + 0.144 × Physical_Activity</p>
<p>Compared to the simple model, the residuals in the multiple regression are noticeably tighter. The minimum is -5.44 and the third quartile is 0.84, meaning that for most students, the model’s predictions are off by less than about one point. The median residual is -0.16, which is very close to zero, indicating that the model does not systematically overpredict or underpredict. However, the maximum residual is still 30.99, indicating that there remains at least one extreme outlier — a student who scored about 31 points higher than predicted. This is slightly smaller than in the simple model (where the maximum was 33.49), suggesting that adding more predictors has helped but has not fully resolved this issue.</p>
<p>The intercept (β̂₀) is now estimated at 40.927. This is substantially lower than in the simple model (61.46), which makes sense. In the simple model, the intercept represented the predicted score when only Hours_Studied was zero. In the multiple model, the intercept represents the predicted score when all six predictors are simultaneously zero — that is, a hypothetical student who studies zero hours, has zero attendance, has zero previous scores, gets zero sleep, has zero tutoring sessions, and does zero physical activity. Such a student is of course entirely hypothetical and unrealistic, which is why we should not over-interpret the intercept in multiple regression. Its main role is mathematical — it anchors the regression plane in the right position.</p>
<p>The coefficient for Hours_Studied is 0.292, which is remarkably similar to its value in the simple regression (0.289). This tells us something important: the relationship between study hours and exam scores is robust — it persists even after we account for the effects of attendance, prior scores, sleep, tutoring, and physical activity. In substantive terms, holding all other factors constant, each additional hour of study per week is associated with an increase of about 0.29 points on the exam. The t-statistic is 57.52 and the p-value is far below any conventional significance threshold, confirming that this relationship is highly statistically significant.</p>
<p>The coefficient for Attendance is 0.198, meaning that each additional percentage point of class attendance is associated with about 0.20 additional points on the exam, after controlling for the other variables. To put this in perspective, a student who attends 90% of classes versus one who attends 70% of classes (a 20 percentage-point difference) would be expected to score about 3.96 points higher, all else being equal. The t-statistic of 75.26 makes this the strongest predictor in the model, and its p-value is essentially zero.</p>
<p>The coefficient for Previous_Scores is 0.048. This means that for each additional point a student earned on their previous assessments, their exam score is expected to increase by about 0.048 points, holding other factors constant. While this effect is statistically significant (t = 22.81, p &lt; 2 × 10⁻¹⁶), it is relatively modest in magnitude. A student whose prior scores are 20 points higher than another student’s would be expected to score only about 0.96 points higher on this exam. This suggests that while past performance does predict future performance, its incremental contribution is small once study habits and attendance are already accounted for.</p>
<p>The coefficient for Sleep_Hours is -0.018. This is the only predictor whose coefficient is not statistically significant in this model. The t-statistic is only -0.871, and the p-value is 0.384 — far above any conventional significance threshold such as 0.05 or 0.01. This means that we cannot reject the null hypothesis that the true coefficient for Sleep_Hours is zero. In other words, after accounting for study hours, attendance, prior scores, tutoring, and physical activity, sleep hours do not appear to have a meaningful linear relationship with exam scores. This does not necessarily mean that sleep is unimportant for academic performance in general — it may be that the effect of sleep is nonlinear, or that its influence is already captured indirectly by the other variables in the model.</p>
<p>The coefficient for Tutoring_Sessions is 0.494, the largest individual slope coefficient in the model. Each additional tutoring session is associated with about half a point increase on the exam. A student who attended 4 tutoring sessions compared to one who attended none would be expected to score about 1.97 points higher. The t-statistic is 20.00 and the p-value is essentially zero, confirming strong statistical significance.</p>
<p>The coefficient for Physical_Activity is 0.144, meaning that each additional hour per week of physical activity is associated with about 0.14 additional exam points, after controlling for the other variables. The t-statistic is 4.89 and the p-value is approximately 0.000001, so this relationship is statistically significant, though its practical magnitude is relatively small.</p>
<p>The Residual Standard Error has decreased from 3.483 in the simple model to 2.467 in the multiple model. This is a substantial improvement — it tells us that the average prediction error has been reduced by about 29%. The model’s predictions are now off by only about 2.47 points on average, compared to 3.48 points when we used study hours alone.</p>
<p>The R² has jumped from 0.1984 to 0.5982. This is a dramatic improvement. The multiple regression model now explains approximately 59.82% of the variation in exam scores, compared to only 19.84% in the simple model. Adding attendance, previous scores, tutoring sessions, and physical activity has nearly tripled the amount of explained variance. The Adjusted R² is 0.5979, which is nearly identical to the regular R², indicating that the additional predictors are genuinely contributing to the model’s explanatory power and are not merely inflating R² artificially.</p>
<p>The F-statistic is 1,638 with a p-value less than 2.2 × 10⁻¹⁶. In the multiple regression context, the F-statistic tests the null hypothesis that all slope coefficients are simultaneously zero (H₀: β₁ = β₂ = … = β₆ = 0). The enormous F-statistic and the effectively zero p-value tell us that we can decisively reject this null hypothesis. At least some — and as we saw, most — of the predictors are significantly related to exam scores.</p>
<p>The confidence intervals for the multiple regression coefficients reinforce our findings. For Hours_Studied, the interval is [0.282, 0.302], which is narrow and entirely above zero — strong evidence of a positive effect. For Attendance, the interval is [0.193, 0.203], also narrow and firmly positive. For Tutoring_Sessions, it is [0.445, 0.542]. For Physical_Activity, it is [0.086, 0.202]. All of these intervals exclude zero, confirming statistical significance.</p>
<p>The crucial exception is Sleep_Hours, whose confidence interval is [-0.059, 0.023]. This interval straddles zero — it includes both negative and positive values — which confirms that we cannot determine with confidence whether sleep hours have a positive, negative, or zero effect on exam scores in this model. This is perfectly consistent with the non-significant p-value of 0.384 that we observed for this variable.</p>
<p>The comparison between the two models illustrates several important principles from the textbook. First, the coefficient for Hours_Studied barely changed between the simple model (0.289) and the multiple model (0.292). This stability suggests that Hours_Studied is not strongly confounded with the other predictors — its relationship with exam scores is genuine and not merely a byproduct of its correlation with other variables. Second, the dramatic increase in R² from 0.198 to 0.598 demonstrates that multiple regression can be far more powerful than simple regression when there are indeed multiple factors at play. Third, the non-significance of Sleep_Hours reminds us that not every predictor we include will turn out to be useful — and this is exactly the kind of finding that helps us build a more parsimonious model by identifying which variables can be dropped without meaningful loss of explanatory power.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./introduction_to_statistical_learning.html" class="pagination-link" aria-label="Introduction to Statistical Learning">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Statistical Learning</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Linear Regression"</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> ""</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="an">number-sections:</span><span class="co"> true</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="an">title-block-banner:</span><span class="co"> "#00868B"</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="an">title-block-banner-color:</span><span class="co"> "white"</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>student_performance <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"datasets/StudentPerformanceFactors.csv"</span>)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>student_performance <span class="ot">&lt;-</span> student_performance <span class="sc">|&gt;</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        <span class="at">Extracurricular_Activities =</span> <span class="fu">case_when</span>(</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>            Extracurricular_Activities <span class="sc">==</span> <span class="st">"Yes"</span> <span class="sc">~</span> <span class="cn">TRUE</span>,</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>            Extracurricular_Activities <span class="sc">==</span> <span class="st">"No"</span> <span class="sc">~</span> <span class="cn">FALSE</span>,</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>            <span class="cn">TRUE</span> <span class="sc">~</span> <span class="cn">NA</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>        <span class="at">Internet_Access =</span> <span class="fu">case_when</span>(</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>            Internet_Access <span class="sc">==</span> <span class="st">"Yes"</span> <span class="sc">~</span> <span class="cn">TRUE</span>,</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>            Internet_Access <span class="sc">==</span> <span class="st">"No"</span> <span class="sc">~</span> <span class="cn">FALSE</span>,</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>            <span class="cn">TRUE</span> <span class="sc">~</span> <span class="cn">NA</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>        <span class="at">Learning_Disabilities =</span> <span class="fu">case_when</span>(</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>            Learning_Disabilities <span class="sc">==</span> <span class="st">"Yes"</span> <span class="sc">~</span> <span class="cn">TRUE</span>,</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>            Learning_Disabilities <span class="sc">==</span> <span class="st">"No"</span> <span class="sc">~</span> <span class="cn">FALSE</span>,</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>            <span class="cn">TRUE</span> <span class="sc">~</span> <span class="cn">NA</span></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rename</span>(</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>        <span class="at">hours_studied =</span> Hours_Studied,</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>        <span class="at">attendance =</span> Attendance,</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>        <span class="at">parental_involvement =</span> Parental_Involvement,</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>        <span class="at">access_to_resources =</span> Access_to_Resources,</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>        <span class="at">extracurricular_activities =</span> Extracurricular_Activities,</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>        <span class="at">sleep_hours =</span> Sleep_Hours,</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>        <span class="at">previous_scores =</span> Previous_Scores,</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>        <span class="at">motivation_level =</span> Motivation_Level,</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>        <span class="at">internet_access =</span> Internet_Access,</span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>        <span class="at">tutoring_sessions =</span> Tutoring_Sessions,</span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>        <span class="at">family_income =</span> Family_Income,</span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>        <span class="at">teacher_quality =</span> Teacher_Quality,</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>        <span class="at">school_type =</span> School_Type,</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>        <span class="at">peer_influence =</span> Peer_Influence,</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>        <span class="at">physical_activity =</span> Physical_Activity,</span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>        <span class="at">learning_disabilities =</span> Learning_Disabilities,</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>        <span class="at">parental_education_level =</span> Parental_Education_Level,</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>        <span class="at">distance_from_home =</span> Distance_from_Home,</span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a>        <span class="at">gender =</span> Gender,</span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>        <span class="at">exam_score =</span> Exam_Score,</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a>The <span class="in">`student_performance`</span> dataset is a large educational dataset that seeks to capture the many different factors that can influence how well a student performs on their final exam. The fundamental research question behind this dataset is: *what predicts student academic achievement, and how strongly does each factor contribute?* This dataset is publicly available on the Kaggle platform, where it was published under the title <span class="co">[</span><span class="ot">Student Performance Factors</span><span class="co">]</span> (https://www.kaggle.com/datasets/lainguyn123/student-performance-factors). The dataset contains 6,607 observations, where each observation represents one individual student. For each student, 20 variables have been recorded. One of these variables is the outcome we want to predict (dependent variable), and the remaining 19 are potential predictors (independent variables). Let us walk you through each of them:</span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"hours_studied" records how many hours per week each student dedicates to studying ranged from 1 to 44 hours,</span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"attendance" represents the percentage of classes each student attended during the course,</span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"parental_involvement" describes the degree to which a student's parents are involved in their education within the three levels (Low, Medium, and High),</span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-68"><a href="#cb12-68" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"access_to_resources" indicates the level of access a student has to educational resources such as textbooks, computers, or online materials within the three levels (Low, Medium, and High),</span>
<span id="cb12-69"><a href="#cb12-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-70"><a href="#cb12-70" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"extracurricular_activities" records whether the student participates in extracurricular activities (<span class="in">`TRUE`</span> or <span class="in">`FALSE`</span>),</span>
<span id="cb12-71"><a href="#cb12-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-72"><a href="#cb12-72" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"sleep_hours" records the average number of hours of sleep the student gets per night,</span>
<span id="cb12-73"><a href="#cb12-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-74"><a href="#cb12-74" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"previous_scores" captures the student's scores from prior academic assessments ranged from 50 to 100,</span>
<span id="cb12-75"><a href="#cb12-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-76"><a href="#cb12-76" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"motivation_level" captures the student's self-reported level of motivation within the three categories (Low, Medium, and High),</span>
<span id="cb12-77"><a href="#cb12-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-78"><a href="#cb12-78" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"internet_access" indicates whether the student has access to the internet (<span class="in">`TRUE`</span> or <span class="in">`FALSE`</span>),</span>
<span id="cb12-79"><a href="#cb12-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-80"><a href="#cb12-80" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"tutoring_sessions" records the number of tutoring sessions the student attended ranged from 0 to 8,</span>
<span id="cb12-81"><a href="#cb12-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-82"><a href="#cb12-82" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"family_income" records the economic status of the student's family, categorized as Low, Medium, or High,</span>
<span id="cb12-83"><a href="#cb12-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-84"><a href="#cb12-84" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"teacher_quality" describes the perceived quality of the student's teachers, categorized as Low, Medium, or High,</span>
<span id="cb12-85"><a href="#cb12-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-86"><a href="#cb12-86" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"school_type" indicates whether the student attends a public or private school,</span>
<span id="cb12-87"><a href="#cb12-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-88"><a href="#cb12-88" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"peer_influence" describes the nature of the influence the student's peer group has on their academic behavior, and it has three levels (Negative, Neutral, and Positive),</span>
<span id="cb12-89"><a href="#cb12-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-90"><a href="#cb12-90" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"physical_activity" measures how many hours per week the student spends on physical activities,</span>
<span id="cb12-91"><a href="#cb12-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-92"><a href="#cb12-92" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"learning_disabilities" records whether the student has been diagnosed with any learning disabilities (<span class="in">`TRUE`</span> or <span class="in">`FALSE`</span>),</span>
<span id="cb12-93"><a href="#cb12-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-94"><a href="#cb12-94" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"parental_education_level" captures the highest level of education achieved by the student's parents, with categories including High School, College, and Postgraduate.</span>
<span id="cb12-95"><a href="#cb12-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-96"><a href="#cb12-96" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"distance_from_home" indicates how far the student lives from their school, categorized as Near, Moderate, or Far,</span>
<span id="cb12-97"><a href="#cb12-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-98"><a href="#cb12-98" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"gender" records the student's gender as either Male or Female,</span>
<span id="cb12-99"><a href="#cb12-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-100"><a href="#cb12-100" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"exam_score" records the score that each student achieved on their final exam ranged from 55 to 101 points.</span>
<span id="cb12-101"><a href="#cb12-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-104"><a href="#cb12-104" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-105"><a href="#cb12-105" aria-hidden="true" tabindex="-1"></a><span class="co"># Pregled podataka</span></span>
<span id="cb12-106"><a href="#cb12-106" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(student_performance)</span>
<span id="cb12-107"><a href="#cb12-107" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-108"><a href="#cb12-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-109"><a href="#cb12-109" aria-hidden="true" tabindex="-1"></a>**Linear regression** is one of the oldest, most fundamental, and most widely used methods in statistics and statistical learning. Despite its simplicity, it remains an essential tool for anyone working with data, especially in the social sciences. The core idea behind linear regression is straightforward: we want to understand and quantify the relationship between one or more explanatory variables and a single outcome variable. More specifically, linear regression assumes that the relationship between the dependent and the independent variable can be described, at least approximately, by a straight line - or in the case of multiple predictors, by a flat surface (a hyperplane) in higher-dimensional space.</span>
<span id="cb12-110"><a href="#cb12-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-111"><a href="#cb12-111" aria-hidden="true" tabindex="-1"></a>The purpose of linear regression is twofold. First, it serves an explanatory purpose: it helps us understand which factors are associated with the outcome and how strongly each factor contributes, while holding the other factors constant. Second, it serves a predictive purpose: once we have estimated the relationship, we can use it to predict the outcome for new observations based on their predictor values. In our student performance example, the central question is: *what factors influence a student's exam score, and by how much?* Linear regression allows us to answer questions such as "*does studying more hours lead to higher exam scores?*" and "*how much additional score can a student expect to gain for each additional hour of study?*"</span>
<span id="cb12-112"><a href="#cb12-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-113"><a href="#cb12-113" aria-hidden="true" tabindex="-1"></a>The simplest form of linear regression involves just one predictor variable. This is called **simple linear regression**. Mathematically, it takes the form:</span>
<span id="cb12-114"><a href="#cb12-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-115"><a href="#cb12-115" aria-hidden="true" tabindex="-1"></a>$Y \approx \beta_0 + \beta_1X$</span>
<span id="cb12-116"><a href="#cb12-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-117"><a href="#cb12-117" aria-hidden="true" tabindex="-1"></a>In this equation, Y is the dependent variable - the outcome we want to predict. In our example, Y is, for example, the "exam_score". X is the independent variable - the factor we believe is related to the outcome. For instance, X could be "hours_studied". The symbol $\beta_0$ is called the **intercept**. It represents the expected value of Y when X equals zero. In our context, it would represent the expected exam score for a hypothetical student who studies zero hours. The symbol $\beta_1$ is called the **slope**. It represents the average change in Y that is associated with a one-unit increase in X. In our example, it tells us how many additional points on the exam a student can expect to gain for each additional hour of studying. Together, $\beta_0$ and $\beta_1$ are called the **model coefficients or parameters**.</span>
<span id="cb12-118"><a href="#cb12-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-119"><a href="#cb12-119" aria-hidden="true" tabindex="-1"></a>Of course, in real life we do not know the true values of $\beta_0$ and $\beta_1$. We must estimate them from the data. Once we have estimated these coefficients - and we denote the estimates with a hat symbol as $\hat{\beta}_0$ and $\hat{\beta}_1$ - we can write our prediction equation as: $y = \hat{\beta_0} + \hat{\beta_1}x$. Here, $\hat{y}$ is the predicted value of the response for a given value x of the predictor. The hat symbol always indicates that we are dealing with an estimate rather than a true, known quantity.</span>
<span id="cb12-120"><a href="#cb12-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-121"><a href="#cb12-121" aria-hidden="true" tabindex="-1"></a>In practice, a single predictor is rarely sufficient to explain all the variation in the response. A student's exam score is not determined by study hours alone - attendance, prior academic performance, tutoring, and many other factors play a role. **Multiple linear regression** extends the simple model to accommodate several predictors simultaneously. The general formula is:</span>
<span id="cb12-122"><a href="#cb12-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-123"><a href="#cb12-123" aria-hidden="true" tabindex="-1"></a>$Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_pX_p + \eta$</span>
<span id="cb12-124"><a href="#cb12-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-125"><a href="#cb12-125" aria-hidden="true" tabindex="-1"></a>In this equation, $X_1, X_2, X_3, ..., X_p$ represent p different predictor variables, and $\beta_1, \beta_2, ..., \betap$ are their corresponding slope coefficients. Each coefficient $\beta_j$ represents the average change in Y associated with a one-unit increase in the predictor $\beta_j$, while holding all other predictors constant. This "holding all other predictors constant" interpretation is crucial and is what distinguishes multiple regression from simply running many separate simple regressions. The term $\epsilon$ represents the error term - it captures everything that our model does not explain, including the influence of unmeasured variables, measurement error, and the inherent randomness in human behavior.</span>
<span id="cb12-126"><a href="#cb12-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-127"><a href="#cb12-127" aria-hidden="true" tabindex="-1"></a>In our Student Performance example, a multiple linear regression model might look like this:</span>
<span id="cb12-128"><a href="#cb12-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-129"><a href="#cb12-129" aria-hidden="true" tabindex="-1"></a>exam_score = $\beta_0$ + $\beta_1$ × hours_studied + $\beta_2$ × attendance + $\beta_3$ × previous_scores + $\beta_4$ × sleep_hours + $\beta_5$ × tutoring_sessions + $\beta_6$ × physical_activity + $\epsilon$</span>
<span id="cb12-130"><a href="#cb12-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-131"><a href="#cb12-131" aria-hidden="true" tabindex="-1"></a>This model allows us to estimate the unique contribution of each predictor to the exam score. For instance, $\beta_1$ tells us the expected change in exam score for each additional hour of study, after accounting for the effects of attendance, previous scores, sleep, tutoring, and physical activity. This is fundamentally different from simple linear regression, where $\beta_1$ would capture the total association between study hours and exam scores without adjusting for any other factor.</span>
<span id="cb12-132"><a href="#cb12-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-133"><a href="#cb12-133" aria-hidden="true" tabindex="-1"></a><span class="fu">## Estimating the Coefficients</span></span>
<span id="cb12-134"><a href="#cb12-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-135"><a href="#cb12-135" aria-hidden="true" tabindex="-1"></a>The key question is: *how do we actually find the best values for our coefficient estimates $\hat{\beta}_0$, $\hat{\beta}_1$, ..., $\hat{\beta}_p$?* The answer lies in the **least squares method**, which is the most common approach for fitting a linear regression model. The basic idea is intuitive: we want our predicted values $\hat{y}_i$ to be as close as possible to the actual observed values $y_0$ for every observation in our dataset.</span>
<span id="cb12-136"><a href="#cb12-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-137"><a href="#cb12-137" aria-hidden="true" tabindex="-1"></a>For each observation i, the difference between the observed value and the predicted value is called the **residual**, denoted $e_i = y_i - \hat{y}_i$. The residual tells us how much our model's prediction misses the actual outcome for that particular student. Some residuals will be positive (when the model underpredicts) and some will be negative (when the model overpredicts). To get an overall measure of how well the model fits all the data, we cannot simply add up the residuals, because the positive and negative ones would cancel each other out. Instead, we square each residual and then sum them all up. This quantity is called the **residual sum of squares** (RSS):</span>
<span id="cb12-138"><a href="#cb12-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-139"><a href="#cb12-139" aria-hidden="true" tabindex="-1"></a>$RSS = e_1^2 + e_2^2 + ... + e_n^2 = \sum(y_i - \hat{y}_i)^2$</span>
<span id="cb12-140"><a href="#cb12-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-141"><a href="#cb12-141" aria-hidden="true" tabindex="-1"></a>The least squares method chooses the coefficient estimates $\hat{\beta}_0$, $\hat{\beta}_1$, ..., $\hat{\beta}_p$ that minimize this RSS. In other words, the least squares approach finds the line (in simple regression) or the hyperplane (in multiple regression) that makes the total squared prediction error as small as possible. This is a well-defined mathematical optimization problem, and the solution can be computed using calculus. For simple linear regression, the formulas for the minimizers have a closed-form expression:</span>
<span id="cb12-142"><a href="#cb12-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-143"><a href="#cb12-143" aria-hidden="true" tabindex="-1"></a>$\hat{\beta}_1 = \frac{\sum_{i = 1}^n(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i = 1}^n(x_i - \bar{x})^2}$</span>
<span id="cb12-144"><a href="#cb12-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-145"><a href="#cb12-145" aria-hidden="true" tabindex="-1"></a>$\hat{\beta}_0 = \bar{y} - \hat{\beta}_1\hat{x}$</span>
<span id="cb12-146"><a href="#cb12-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-147"><a href="#cb12-147" aria-hidden="true" tabindex="-1"></a>Here, $\bar{x}$ and $\bar{y}$ are the sample means of the predictor and the response, respectively. The formula for $\hat{\beta}_1$ has an intuitive interpretation: it measures the degree to which X and Y vary together (the numerator captures their joint variation) relative to the total variation in X (the denominator). For multiple linear regression, the coefficient estimates are computed using matrix algebra, which is handled automatically by statistical software such as R.</span>
<span id="cb12-148"><a href="#cb12-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-149"><a href="#cb12-149" aria-hidden="true" tabindex="-1"></a>The beauty of the least squares method is that it provides a principled, objective way to estimate the model parameters. It does not require any subjective judgment about what the "best" line should look like - the method simply finds the line that minimizes the total squared distance between the observed data points and the fitted line.</span>
<span id="cb12-150"><a href="#cb12-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-151"><a href="#cb12-151" aria-hidden="true" tabindex="-1"></a><span class="fu">## Applying Linear Regression to Our Example in R</span></span>
<span id="cb12-152"><a href="#cb12-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-153"><a href="#cb12-153" aria-hidden="true" tabindex="-1"></a>Now let us apply these concepts to our <span class="in">`student_performance`</span> dataset. We will fit both a simple linear regression (predicting "exam_score" from "hours_studied" alone) and a multiple linear regression (predicting "exam_score" from six quantitative predictors). Below is the R code that accomplishes this.</span>
<span id="cb12-154"><a href="#cb12-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-155"><a href="#cb12-155" aria-hidden="true" tabindex="-1"></a>To fit a simple linear regression model in R, we use the <span class="in">`lm()`</span> function, which stands for linear model. The syntax follows the pattern <span class="in">`lm(response ~ predictor, data = dataset)`</span>. The tilde symbol (<span class="in">`~`</span>) can be read as "*is modeled as a function of*". For our simple linear regression of "exam_score" onto "hours_studied", we write:</span>
<span id="cb12-156"><a href="#cb12-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-159"><a href="#cb12-159" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-160"><a href="#cb12-160" aria-hidden="true" tabindex="-1"></a>simple_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(exam_score <span class="sc">~</span> hours_studied, <span class="at">data =</span> student_performance)</span>
<span id="cb12-161"><a href="#cb12-161" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(simple_model)</span>
<span id="cb12-162"><a href="#cb12-162" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(simple_model)</span>
<span id="cb12-163"><a href="#cb12-163" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-164"><a href="#cb12-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-165"><a href="#cb12-165" aria-hidden="true" tabindex="-1"></a>The <span class="in">`lm()`</span> function fits the model by computing the least squares coefficient estimates. The <span class="in">`summary()`</span> function then provides a detailed output that includes the estimated coefficients, their standard errors, t-statistics, p-values, the residual standard error, and the $R^2$ statistic. The <span class="in">`confint()`</span> function computes the 95% confidence intervals for each coefficient estimate, which tell us the range of plausible values for the true population parameters.</span>
<span id="cb12-166"><a href="#cb12-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-167"><a href="#cb12-167" aria-hidden="true" tabindex="-1"></a>The first block of the output reports a summary of the residuals — the differences between the actual exam scores and the scores predicted by the model. R provides five summary statistics: the minimum residual (-8.532), the first quartile (-2.243), the median (-0.111), the third quartile (2.046), and the maximum residual (33.493). These numbers give us a quick sense of how the model's prediction errors are distributed. Ideally, we would like the residuals to be roughly symmetrically distributed around zero, which would indicate that the model overpredicts and underpredicts with roughly equal frequency and magnitude. In our case, the median is very close to zero (-0.111), and the first and third quartiles are roughly symmetric in magnitude (-2.243 and 2.046), which is encouraging. However, the maximum residual of 33.493 is strikingly large compared to the minimum of -8.532. This tells us that there is at least one student whose actual exam score was about 33.5 points higher than what the model predicted. This large positive outlier suggests that there are some unusually high-performing students whose scores are not well explained by study hours alone — something we should keep in mind and investigate further.</span>
<span id="cb12-168"><a href="#cb12-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-169"><a href="#cb12-169" aria-hidden="true" tabindex="-1"></a>The coefficients table is the heart of the regression output. It reports four pieces of information for each coefficient: the estimate, its standard error, the t-statistic, and the p-value.</span>
<span id="cb12-170"><a href="#cb12-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-171"><a href="#cb12-171" aria-hidden="true" tabindex="-1"></a>The intercept (β̂₀) is estimated at 61.457. This means that when Hours_Studied equals zero, the model predicts an exam score of approximately 61.46 points. In substantive terms, a hypothetical student who does not study at all would be expected to score about 61.5 on the exam, according to this model. This makes intuitive sense — students would still have some baseline level of knowledge from attending classes, even without additional study outside the classroom.</span>
<span id="cb12-172"><a href="#cb12-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-173"><a href="#cb12-173" aria-hidden="true" tabindex="-1"></a>The slope for Hours_Studied (β̂₁) is estimated at 0.289. This is the key coefficient for our research question. It tells us that for each additional hour of study per week, a student's exam score is expected to increase by approximately 0.29 points, on average. So a student who studies 10 hours more per week than another student would be expected to score about 2.89 points higher on the exam. The direction of the relationship is positive, which aligns with our intuition that more studying leads to better performance.</span>
<span id="cb12-174"><a href="#cb12-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-175"><a href="#cb12-175" aria-hidden="true" tabindex="-1"></a>The standard error of each coefficient tells us how precisely the coefficient has been estimated. For the intercept, the standard error is 0.149, and for the slope it is 0.00715. These are quite small relative to the coefficient estimates themselves, which indicates that our estimates are very precise — this is largely a consequence of having a very large sample size of 6,607 observations. The larger the sample, the more precisely we can estimate the regression coefficients, because we have more information to work with.</span>
<span id="cb12-176"><a href="#cb12-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-177"><a href="#cb12-177" aria-hidden="true" tabindex="-1"></a>The t-statistic is calculated by dividing the coefficient estimate by its standard error. For the intercept, the t-value is 411.92 (which is 61.457 divided by 0.149), and for Hours_Studied the t-value is 40.44 (which is 0.289 divided by 0.00715). The t-statistic measures how many standard errors the coefficient estimate is away from zero. A large t-statistic indicates that the coefficient is far from zero relative to its uncertainty, which provides strong evidence that the true coefficient is not zero.</span>
<span id="cb12-178"><a href="#cb12-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-179"><a href="#cb12-179" aria-hidden="true" tabindex="-1"></a>The p-value, shown in the column labeled Pr(&gt;|t|), tells us the probability of observing a t-statistic as extreme as the one we calculated, under the assumption that the true coefficient is actually zero (that is, under the null hypothesis that there is no relationship between the predictor and the response). For both the intercept and Hours_Studied, the p-value is reported as less than 2 × 10⁻¹⁶, which is essentially zero. This means that the probability of seeing such strong evidence for a relationship if no relationship actually existed is vanishingly small. The three asterisks (***) next to the p-values indicate the highest level of statistical significance. We can therefore confidently reject the null hypothesis that β₁ = 0, and conclude that there is a statistically significant positive relationship between Hours_Studied and Exam_Score.</span>
<span id="cb12-180"><a href="#cb12-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-181"><a href="#cb12-181" aria-hidden="true" tabindex="-1"></a>Below the coefficients table, R provides several statistics that describe the overall quality of the model.</span>
<span id="cb12-182"><a href="#cb12-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-183"><a href="#cb12-183" aria-hidden="true" tabindex="-1"></a>The Residual Standard Error (RSE) is 3.483. This is an estimate of the standard deviation of the error term ε. In practical terms, it tells us that the actual exam scores deviate from the model's predictions by approximately 3.48 points on average. Given that the mean exam score is about 67.24, this represents a percentage error of roughly 5.2% (3.483 / 67.24), which is moderate. It means that even after accounting for study hours, there is still considerable unexplained variation in exam scores — many other factors besides study time contribute to how well a student performs.</span>
<span id="cb12-184"><a href="#cb12-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-185"><a href="#cb12-185" aria-hidden="true" tabindex="-1"></a>The R² (R-squared) statistic is 0.1984. This is one of the most important measures of model fit. R² represents the proportion of the total variance in the response variable that is explained by the model. In our case, R² = 0.1984 means that Hours_Studied alone explains approximately 19.84% of the variation in exam scores. The remaining 80% of the variation is due to other factors that are not included in this model. While 19.84% is a meaningful amount of explanatory power — it confirms that study hours do matter — it also makes clear that study hours alone are far from sufficient to explain student performance. This is exactly what motivates us to move from simple to multiple linear regression: by adding more predictors, we hope to explain a larger share of the variation.</span>
<span id="cb12-186"><a href="#cb12-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-187"><a href="#cb12-187" aria-hidden="true" tabindex="-1"></a>The Adjusted R² is 0.1983, which is virtually identical to the regular R² in this case. The adjusted version penalizes the model slightly for each additional predictor it includes, to guard against the artificial inflation of R² that occurs when irrelevant predictors are added. With only one predictor, the penalty is negligible, so the two values are nearly the same.</span>
<span id="cb12-188"><a href="#cb12-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-189"><a href="#cb12-189" aria-hidden="true" tabindex="-1"></a>The F-statistic is 1,635, with a p-value less than 2.2 × 10⁻¹⁶. The F-statistic tests the overall null hypothesis that all slope coefficients in the model are zero — in other words, that none of the predictors are related to the response. In simple linear regression with just one predictor, this test is equivalent to the t-test for β₁. The extremely large F-statistic and the essentially zero p-value confirm that the model as a whole is statistically significant: Hours_Studied is clearly related to Exam_Score.</span>
<span id="cb12-190"><a href="#cb12-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-191"><a href="#cb12-191" aria-hidden="true" tabindex="-1"></a>The confidence intervals provide a range of plausible values for each true population coefficient. For the intercept, the 95% confidence interval is <span class="co">[</span><span class="ot">61.16, 61.75</span><span class="co">]</span>, meaning we are 95% confident that the true baseline exam score (when study hours are zero) lies between 61.16 and 61.75 points. For Hours_Studied, the 95% confidence interval is <span class="co">[</span><span class="ot">0.275, 0.303</span><span class="co">]</span>. This means we are 95% confident that the true effect of one additional hour of study is an increase in exam score between 0.275 and 0.303 points. Importantly, this interval does not include zero, which is consistent with our finding that the relationship is statistically significant. If zero were included in this interval, it would mean that a null effect (no relationship) would be a plausible value, and we could not reject the null hypothesis.</span>
<span id="cb12-192"><a href="#cb12-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-193"><a href="#cb12-193" aria-hidden="true" tabindex="-1"></a>For the multiple linear regression model, we simply add more predictors to the right side of the formula, separated by the + sign:</span>
<span id="cb12-194"><a href="#cb12-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-197"><a href="#cb12-197" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb12-198"><a href="#cb12-198" aria-hidden="true" tabindex="-1"></a>multiple_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(exam_score <span class="sc">~</span> hours_studied <span class="sc">+</span> attendance <span class="sc">+</span> previous_scores <span class="sc">+</span> sleep_hours <span class="sc">+</span> tutoring_sessions <span class="sc">+</span> physical_activity, <span class="at">data =</span> student_performance)</span>
<span id="cb12-199"><a href="#cb12-199" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(multiple_model)</span>
<span id="cb12-200"><a href="#cb12-200" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(multiple_model)</span>
<span id="cb12-201"><a href="#cb12-201" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-202"><a href="#cb12-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-203"><a href="#cb12-203" aria-hidden="true" tabindex="-1"></a>This tells R to fit a model that predicts "exam_score" using all six quantitative predictors simultaneously. The least squares method will estimate a separate slope coefficient for each predictor, along with a single intercept, by minimizing the total RSS across all 6,607 observations.</span>
<span id="cb12-204"><a href="#cb12-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-205"><a href="#cb12-205" aria-hidden="true" tabindex="-1"></a>Our multiple linear regression model includes six quantitative predictors simultaneously. The estimated model can be written as:</span>
<span id="cb12-206"><a href="#cb12-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-207"><a href="#cb12-207" aria-hidden="true" tabindex="-1"></a>Exam_Score ≈ 40.93 + 0.292 × Hours_Studied + 0.198 × Attendance + 0.048 × Previous_Scores − 0.018 × Sleep_Hours + 0.494 × Tutoring_Sessions + 0.144 × Physical_Activity</span>
<span id="cb12-208"><a href="#cb12-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-209"><a href="#cb12-209" aria-hidden="true" tabindex="-1"></a>Compared to the simple model, the residuals in the multiple regression are noticeably tighter. The minimum is -5.44 and the third quartile is 0.84, meaning that for most students, the model's predictions are off by less than about one point. The median residual is -0.16, which is very close to zero, indicating that the model does not systematically overpredict or underpredict. However, the maximum residual is still 30.99, indicating that there remains at least one extreme outlier — a student who scored about 31 points higher than predicted. This is slightly smaller than in the simple model (where the maximum was 33.49), suggesting that adding more predictors has helped but has not fully resolved this issue.</span>
<span id="cb12-210"><a href="#cb12-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-211"><a href="#cb12-211" aria-hidden="true" tabindex="-1"></a>The intercept (β̂₀) is now estimated at 40.927. This is substantially lower than in the simple model (61.46), which makes sense. In the simple model, the intercept represented the predicted score when only Hours_Studied was zero. In the multiple model, the intercept represents the predicted score when all six predictors are simultaneously zero — that is, a hypothetical student who studies zero hours, has zero attendance, has zero previous scores, gets zero sleep, has zero tutoring sessions, and does zero physical activity. Such a student is of course entirely hypothetical and unrealistic, which is why we should not over-interpret the intercept in multiple regression. Its main role is mathematical — it anchors the regression plane in the right position.</span>
<span id="cb12-212"><a href="#cb12-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-213"><a href="#cb12-213" aria-hidden="true" tabindex="-1"></a>The coefficient for Hours_Studied is 0.292, which is remarkably similar to its value in the simple regression (0.289). This tells us something important: the relationship between study hours and exam scores is robust — it persists even after we account for the effects of attendance, prior scores, sleep, tutoring, and physical activity. In substantive terms, holding all other factors constant, each additional hour of study per week is associated with an increase of about 0.29 points on the exam. The t-statistic is 57.52 and the p-value is far below any conventional significance threshold, confirming that this relationship is highly statistically significant.</span>
<span id="cb12-214"><a href="#cb12-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-215"><a href="#cb12-215" aria-hidden="true" tabindex="-1"></a>The coefficient for Attendance is 0.198, meaning that each additional percentage point of class attendance is associated with about 0.20 additional points on the exam, after controlling for the other variables. To put this in perspective, a student who attends 90% of classes versus one who attends 70% of classes (a 20 percentage-point difference) would be expected to score about 3.96 points higher, all else being equal. The t-statistic of 75.26 makes this the strongest predictor in the model, and its p-value is essentially zero.</span>
<span id="cb12-216"><a href="#cb12-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-217"><a href="#cb12-217" aria-hidden="true" tabindex="-1"></a>The coefficient for Previous_Scores is 0.048. This means that for each additional point a student earned on their previous assessments, their exam score is expected to increase by about 0.048 points, holding other factors constant. While this effect is statistically significant (t = 22.81, p &lt; 2 × 10⁻¹⁶), it is relatively modest in magnitude. A student whose prior scores are 20 points higher than another student's would be expected to score only about 0.96 points higher on this exam. This suggests that while past performance does predict future performance, its incremental contribution is small once study habits and attendance are already accounted for.</span>
<span id="cb12-218"><a href="#cb12-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-219"><a href="#cb12-219" aria-hidden="true" tabindex="-1"></a>The coefficient for Sleep_Hours is -0.018. This is the only predictor whose coefficient is not statistically significant in this model. The t-statistic is only -0.871, and the p-value is 0.384 — far above any conventional significance threshold such as 0.05 or 0.01. This means that we cannot reject the null hypothesis that the true coefficient for Sleep_Hours is zero. In other words, after accounting for study hours, attendance, prior scores, tutoring, and physical activity, sleep hours do not appear to have a meaningful linear relationship with exam scores. This does not necessarily mean that sleep is unimportant for academic performance in general — it may be that the effect of sleep is nonlinear, or that its influence is already captured indirectly by the other variables in the model.</span>
<span id="cb12-220"><a href="#cb12-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-221"><a href="#cb12-221" aria-hidden="true" tabindex="-1"></a>The coefficient for Tutoring_Sessions is 0.494, the largest individual slope coefficient in the model. Each additional tutoring session is associated with about half a point increase on the exam. A student who attended 4 tutoring sessions compared to one who attended none would be expected to score about 1.97 points higher. The t-statistic is 20.00 and the p-value is essentially zero, confirming strong statistical significance.</span>
<span id="cb12-222"><a href="#cb12-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-223"><a href="#cb12-223" aria-hidden="true" tabindex="-1"></a>The coefficient for Physical_Activity is 0.144, meaning that each additional hour per week of physical activity is associated with about 0.14 additional exam points, after controlling for the other variables. The t-statistic is 4.89 and the p-value is approximately 0.000001, so this relationship is statistically significant, though its practical magnitude is relatively small.</span>
<span id="cb12-224"><a href="#cb12-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-225"><a href="#cb12-225" aria-hidden="true" tabindex="-1"></a>The Residual Standard Error has decreased from 3.483 in the simple model to 2.467 in the multiple model. This is a substantial improvement — it tells us that the average prediction error has been reduced by about 29%. The model's predictions are now off by only about 2.47 points on average, compared to 3.48 points when we used study hours alone.</span>
<span id="cb12-226"><a href="#cb12-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-227"><a href="#cb12-227" aria-hidden="true" tabindex="-1"></a>The R² has jumped from 0.1984 to 0.5982. This is a dramatic improvement. The multiple regression model now explains approximately 59.82% of the variation in exam scores, compared to only 19.84% in the simple model. Adding attendance, previous scores, tutoring sessions, and physical activity has nearly tripled the amount of explained variance. The Adjusted R² is 0.5979, which is nearly identical to the regular R², indicating that the additional predictors are genuinely contributing to the model's explanatory power and are not merely inflating R² artificially.</span>
<span id="cb12-228"><a href="#cb12-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-229"><a href="#cb12-229" aria-hidden="true" tabindex="-1"></a>The F-statistic is 1,638 with a p-value less than 2.2 × 10⁻¹⁶. In the multiple regression context, the F-statistic tests the null hypothesis that all slope coefficients are simultaneously zero (H₀: β₁ = β₂ = ... = β₆ = 0). The enormous F-statistic and the effectively zero p-value tell us that we can decisively reject this null hypothesis. At least some — and as we saw, most — of the predictors are significantly related to exam scores.</span>
<span id="cb12-230"><a href="#cb12-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-231"><a href="#cb12-231" aria-hidden="true" tabindex="-1"></a>The confidence intervals for the multiple regression coefficients reinforce our findings. For Hours_Studied, the interval is <span class="co">[</span><span class="ot">0.282, 0.302</span><span class="co">]</span>, which is narrow and entirely above zero — strong evidence of a positive effect. For Attendance, the interval is <span class="co">[</span><span class="ot">0.193, 0.203</span><span class="co">]</span>, also narrow and firmly positive. For Tutoring_Sessions, it is <span class="co">[</span><span class="ot">0.445, 0.542</span><span class="co">]</span>. For Physical_Activity, it is <span class="co">[</span><span class="ot">0.086, 0.202</span><span class="co">]</span>. All of these intervals exclude zero, confirming statistical significance.</span>
<span id="cb12-232"><a href="#cb12-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-233"><a href="#cb12-233" aria-hidden="true" tabindex="-1"></a>The crucial exception is Sleep_Hours, whose confidence interval is <span class="co">[</span><span class="ot">-0.059, 0.023</span><span class="co">]</span>. This interval straddles zero — it includes both negative and positive values — which confirms that we cannot determine with confidence whether sleep hours have a positive, negative, or zero effect on exam scores in this model. This is perfectly consistent with the non-significant p-value of 0.384 that we observed for this variable.</span>
<span id="cb12-234"><a href="#cb12-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-235"><a href="#cb12-235" aria-hidden="true" tabindex="-1"></a>The comparison between the two models illustrates several important principles from the textbook. First, the coefficient for Hours_Studied barely changed between the simple model (0.289) and the multiple model (0.292). This stability suggests that Hours_Studied is not strongly confounded with the other predictors — its relationship with exam scores is genuine and not merely a byproduct of its correlation with other variables. Second, the dramatic increase in R² from 0.198 to 0.598 demonstrates that multiple regression can be far more powerful than simple regression when there are indeed multiple factors at play. Third, the non-significance of Sleep_Hours reminds us that not every predictor we include will turn out to be useful — and this is exactly the kind of finding that helps us build a more parsimonious model by identifying which variables can be dropped without meaningful loss of explanatory power.</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>